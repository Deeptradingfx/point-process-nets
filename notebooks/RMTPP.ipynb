{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1130493d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1, 1, 0, 1, 0, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "m = nn.Linear(2,3)\n",
    "in_ = torch.randn(4,2)\n",
    "out_ = m(in_)\n",
    "\n",
    "\n",
    "torch.randn(10)  > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([1,2,2])\n",
    "torch.cumsum(A,dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rmtpp(nn.Module):\n",
    "    \n",
    "    def __init__(self,marker_dim):\n",
    "        super(Rmtpp, self).__init__()\n",
    "        #embedding yj for a more compact and efficient representation\n",
    "        self.embedding = nn.Linear(1,1)\n",
    "        #linear transformation\n",
    "        self.lin_op = nn.linear(3,1) \n",
    "        self.vt = nn.linear(1,1)\n",
    "        #weights\n",
    "        self.w_t = torch.rand(1) \n",
    "        self.w = torch.rand(1) \n",
    "        self.V_y = torch.rand(marker_dim)\n",
    "        self.b_y = torch.rand(marker_dim) #bias\n",
    "        #functions\n",
    "    \n",
    "    #compute the function fstar\n",
    "    def fstart(t,tj,hj):\n",
    "        return torch.exp(self.vt(hj) + self.w_t*(t-tj) + 1/self.w * torch.exp(self.vt(hj)) -1/w * torch.exp(self.vt(hj) + self.w_t*(t-tj)))\n",
    "    \n",
    "    #compute integral of t*fstart(t) for tj to infinity using monteCarlo method\n",
    "    def numerical_mean(tj,N = 10000):\n",
    "        samp = torch.randn(N)\n",
    "        sample = torch.sqrt(2*F.math.pi) * torch.exp(1/2 * samp**2) * samp * fstart(samp)\n",
    "        #I select only value greater than tj\n",
    "        sample = torch.dot(samp>tj,sample) \n",
    "        #then cumsum of sample \n",
    "        return torch.cumsum(sample,dim=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, tim\"e, marker, hidden_state):\n",
    "        #I first compute next time\n",
    "        time = numerical_mean(time, N =10000)\n",
    "        #Then next marker\n",
    "        marker = ?\n",
    "        #Finally next hidden_state\n",
    "        embedding = self.embedding(marker)\n",
    "        input_ = torch.cat(embedding, time, hidden_state)\n",
    "        hidden_state = F.relu(self.lin_op(input_))\n",
    "        \n",
    "        \n",
    "        \n",
    "        return logprob, logfstar, hidden_state\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
