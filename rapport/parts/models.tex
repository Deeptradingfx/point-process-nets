% !TeX spellcheck = fr_FR
\documentclass[../main.tex]{subfiles}

\begin{document}

Un processus ponctuel est associé à un processus de comptage $N_t$ qui compte le nombre d'événements sur $[0,t]$. Le nombre d'événements entre deux instants $s\leq t$ est donc $N_t - N_s$. Sa mesure d'intensité $\lambda$ par rapport à une filtration $\mathds F = (\mathcal{F}_t)$ est définie\footnotemark~par
\[
	P(N_{t+h} - N_t = 1\mid \mathcal{F}_t) \underset{h\to 0}{=} \lambda_th + o(h).
\]
\footnotetext{On remarquera que comme $P(N_{t+h}-N_t > 1\mid \mathcal{F}_t) = o(h)$, on a aussi, en notation synthétique, $\EE[dN_t\mid\mathcal{F}_t] = \lambda_t\,dt$.}

Ainsi, plus l'intensité $\lambda_t$ est élevée, plus la probabilité d'avoir un événement dans l'immédiat est élevée.

On cherche ici à modéliser des \textit{séquences} d'événements ${\{(t_i,k_i)\}}_i$ arrivant à des instants distincts $0<t_1 < \cdots$ et de \textit{type} $k_i$.

Si on se donne un modèle $P = \PP(\,\cdot\,\mid \Theta)$ de la loi de nos séquences d'événements, la probabilité que $I$ événements $t_1<\cdots<t_I$ surviennent entre les instants $0$ et $T > 0$ a une log-vraisemblance
\begin{equation}\label{eq:likelihood}
	\mathcal{L} =
	\log P(\{(t_i,k_i)\}_{i\in\llbracket 1,I\rrbracket}) =
	\sum_{i=1}^{I} \log P((t_i,k_i)\mid \mathcal{F}_{t_{i-1}}, t_i)
	+ \log P(t_{I+1}>T\mid \mathcal{F}_{t_{I}})
\end{equation}
où $\mathcal{F}_t = \{ (t_i,k_i)\,:\, t \leq t_i \}$.


\subsection{Modèle de base: le processus de Hawkes}

Le processus de Hawkes est un modèle élémentaire de processus ponctuel dépendant de son propre passé. Conditionnellement au passé du processus, son intensité s'écrit sous la forme (vectorielle)
\begin{equation}
\lambda_t = \mu_t + \int_0^t g(t-s)\,dN_s
\end{equation}
où:\begin{itemize}
	\item $N^i_t$ est le nombre total d'événements de type $i$ (la mesure $dN^i_t$ compte le nombre d'événements entre $t$ et $t+dt$),
	\item $\lambda_t^i$ est l'intensité des événements de type $i$,
	\item $\mu^i_t$ est l'intensité de base des événements de type $i$,
	\item $g(t) \in \RR^{K\times K}$ est le \textit{noyau} d'excitation: le coefficient $g_{ij} \geq 0$ contrôle le degré selon lequel les événements de type $j$ influencent l'arrivée des événements de type $j$.
\end{itemize} 

\subsection{Réseaux de neurones récurrents}

Les réseaux de neurones récurrents (\textit{recurrent neural networks}, RNN), sont des modèles de réseaux de neurones avec mémoire, qui prennent en compte l'historique entier de leurs \textit{inputs} au cours de leur entraînement, via un vecteur $h\in\RR^D$ (appelé état caché, \textit{hidden state}), mis à jour à chaque passage dans le réseau (voir la \autoref{fig:simpleRNN}). L'entier $D$ est la dimension cachée du réseau.

Ces modèles récurrents sont surtout utilisés pour la compréhension de texte (vocabulaire, syntaxe\ldots), où ils se sont montrés assez efficaces. \cite{unreasonableEffectivenessRNN}

\begin{figure}
	\centering
	\includegraphics[height=0.2\textheight]{diagrams/rnn.pdf}
	\caption{Les modèles RNN impliquent des boucle: la sortie $h_t$ est utilisée calculer $h_{t+1}$.}\label{fig:simpleRNN}
\end{figure}

\subsubsection{Réseau récurrent avec amortissement (Decay-RNN)}

On postule que l'intensité est de la forme
\begin{equation}\label{eq:decayrnnhiddenstate}
\lambda_t = f(W_l h(t))
\end{equation}
où l'état caché $h(t)\in\RR^D$ est continu. Il s'agit d'une variante du réseau RNN standard, inspiré du modèle <<~\textit{Neural Hawkes process}~>> de \citeauthor{meiEisnerNeuralHawkes} \cite{meiEisnerNeuralHawkes}, qui lui utilise un réseau LSTM (\textit{Long Short-Term Memory network}).

Le réseau prend en entrée l'intervalle de temps $\Delta t_i$ entre deux événements et le type $k_i$ de l'événement en $t_i$, représenté par un vecteur $x_i\in{\{0,1\}}^K$ tel que $(x_i)_j = \mathds{1}_{\{k_i = j\}}$, technique qui s'appelle encodage \textit{one-hot}\footnotemark.
Le temps écoulé depuis un événement en $t_{i-1}$ est pris en compte par amortissement
\begin{equation}
h(t) = h_{i}e^{-\delta_i(t-t_{i-1})},\quad t\in(t_{i-1},t_i]
\end{equation}
où les paramètres $h_i$ et $\delta_i$ sont mis à jour pour l'intervalle $(t_i,t_{i+1}]$ via les équations
\begin{subequations}
\begin{align}
	h_{i+1} &= \tanh(W_{hh}h(t_i) + W_{xh}x_i + b_{h})\quad\text{(\textit{hidden layer})} \\
	\delta_{i+1} &= f(W_{hd}h(t_i) + W_{xd}x_i + b_d).
\end{align}
\end{subequations}
\footnotetext{Ainsi, si $K=3$ et $k_i = 2$, alors $x_i = {(0,1,0)}^\intercal$}

La fonction d'activation $f$ est une approximation de classe $\mathcal C^1$ et strictement positive de la fonction ReLU ($x\mapsto \max(x,0)$), la fonction <<~Softmax~>>
\[
x\mapsto \frac{1}{\beta}\log(1+e^{\beta x}),\quad\beta > 0.
\]
\end{document}