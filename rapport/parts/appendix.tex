% !TeX spellcheck = fr_FR
\documentclass[../main.tex]{subfiles}

\begin{document}

\section{Algorithmes}\label{sec:algoAppendix}

\subsection{Calcul de la log-vraisemblance}\label{ssec:likelihoodComputation}

La log-vraisemblance donnée par la relation \eqref{eq:explicitLikelihood} comporte deux termes: une somme de logarithmes d'intensités et l'intégrale $\int_0^T \bar\lambda_t \,dt$ de l'intensité totale du processus.

\paragraph{Somme des log-intensités.} Le premier terme pose un léger problème au niveau de l'implémentation. Le calcul des intensités ${(\lambda_{t_i})}_i$ donne un tenseur \verb|intens_ti| de format $I\times B\times K$, avec $B$ la taille du \textit{batch} (le sous-ensemble d'entraînement que l'on est en train de traiter). Extraire les $\lambda^{k_i}_{t_i}$ ne peut pas se faire par indexation (par exemple en faisant \verb|intens_ti[:, :, event_types]|).

L'astuce utilisée exploite la représentation des types $k_i$ par encodage \textit{one-hot} avec des vecteurs $u_i\in{\{0,1\}}^K$, définis par $(u_i)_j = \mathds{1}_{\{k_i = j\}}$.\footnotemark En notant $\odot$ le produit terme-à-terme, la relation
\[
\lambda^{k_i}_{t_i} = \sum_{k=1}^K {(\lambda_{t_i} \odot u_i)}_k,
\]
permet d'obtenir les intensités par produit et réduction.
\footnotetext{Ainsi, si $K=3$ et $k_i = 2$, alors $u_i = {(0,1,0)}^\intercal$}


\paragraph{Estimation de l'intégrale.} Étant donné une famille de variables aléatoires iid $\tau^{(m)}\sim\mathcal{U}([0,T])$ indépendantes de la filtration $\mathds{F}$, la quantité 
\[
\bar{\Lambda}_M = \frac{1}{M}\sum_{m=1}^{M}T \bar\lambda_{\tau^{(m)}} \mathbf 1
\]
est un estimateur non biaisé et convergent de l'intégrale, suggéré dans \cite[16]{meiEisnerNeuralHawkes}. Mais il est peu commode pour le calcul en pratique: étant donné le temps $\tau$, il faut savoir à quel intervalle $(t_{i-1}, t_i]$ il appartient pour calculer $\lambda_\tau$, puisque l'expression de l'intensité est définie par morceaux.

En utilisant la relation de Chasles, on peut construire l'estimateur (non biaisé et convergent) suivant:
\begin{equation}
\hat{\Lambda}_M^C = \frac{1}{M}\sum_{m=1}^{M}\left[ \sum_{i=1}^{I} \Delta t_i \bar\lambda_{\tau^{(m)}_i} + (T-t_{I}) \bar\lambda_{\tau^{(m)}_{I+1}}\right]
\approx
\int_0^T \lambda_t\,dt
\end{equation}
où les $\tau_i^{(m)}\sim\mathcal{U}([t_{i-1}, t_i])$, $\tau_{I+1}^{(m)}\sim\mathcal{U}([t_I, T])$ sont indépendants. Le problème de savoir à quel intervalle appartient $\tau$ est levé. Cependant, on n'a aucune garantie que $\hat{\Lambda}^C$ soit un meilleur ou pire estimateur que $\bar{\Lambda}$ en terme de variance.

\subsection{Simulation de processus}\label{ssec:thinning}

\paragraph{Algorithme de \textit{thinning}} \citeauthor{ogata1981} propose un procédé général pour la simulation de processus ponctuels suivant une intensité stochastique $\lambda$ adaptée à une filtration $\mathds{F}$. Il s'agit de trouver un processus constant par morceaux et $\mathds{F}$-adapté $\{\lambda_t^*\}$ tel que $\sum_{k=1}^{K}\lambda^k_t \leq \lambda_t^*$, et de simuler les temps d'arrivée des événements et leur type par une méthode de rejet. \autocite{ogata1981}

En pratique, pour des processus où l'intensité dépend du passé (comme Hawkes ou les modèles neuronaux), le processus majorant $\lambda^*$ doit être construit en même temps, au fur et à mesure que l'on simule des événements. Pour nos modèles, étant donné un événement en $t_i$, l'intensité du processus évolue de manière déterministe conditionnellement à $\mathcal{F}_{t_i}$ pour $t_i\leq t\leq t_{i+1}$: on peut donc calculer un majorant $\lambda_i^* = \lambda^*_{t_i}$.

Une méthode efficace décrite dans la littérature est de choisir la date du prochain événement selon un processus de poisson déterministe d'intensité ${\{\sum_k\lambda^k_t\}}_{t\geq t_i}$ par rejet: on simule des temps $s_j^*\geq t_i$ distribués selon un processus de Poisson homogène d'intensité $\lambda_i^*$, jusqu'à en accepter un comme étant $t_{i+1}$ avec probabilité $\sum_k\lambda^k_{s_j^*}/\lambda^*_{i} \leq 1$. Le choix de $k_{i+1}$ est effectué en sélectionnant un élément $k$ dans $\llbracket 1,K\rrbracket$ avec la distribution $\PP(k_{i+1} = k) = \lambda^{k}_{t_{i+1}}/\sum_p \lambda^p_{t_{i+1}}$. \cite{meiEisnerNeuralHawkes,ogata1981}

Pour avoir un algorithme de simulation efficace, on chercherait à avoir $\lambda^*$ aussi proche de $\lambda$ que possible, de sorte à ce que la méthode de rejet ait une forte probabilité d'accepter un des premiers temps $s_j^*$ proposés.\footnotemark

\footnotetext{Pour réaliser des courbes d'intensité des processus simulés, on peut choisir de simuler les $s_j^*$ selon un processus de Poisson d'intensité $10\lambda^*$, et enregistrer les points $(s_j^*, \lambda^k_{s_j^*})$ supplémentaires pour faire le graphe.}

\paragraph{Majorant $\lambda^*$ pour le RNN} L'intensité s'écrit sous la forme \eqref{eq:decayRNNintensity} $\lambda_t = f(W_lh(t))$. La fonction d'activation $f$ est toujours strictement croissante, donc il suffit en fait de majorer les composantes de $W_lh(t)$, qui s'écrivent sous la forme
\[
	\sum_{j=1}^D {[W_l]}_{kj}h^k_{i}\exp(-\delta^k_i(t-t_{i-1}))
\]
dont les termes se majorent par
\[
	\overline{M}_{kj} = \begin{cases}
	{[W_l]}_{kj}h^k_i &\mbox{si }{[W_l]}_{kj}h^k_i \geq 0 \\
	0 &\mbox{sinon}
	\end{cases}
\]
pour obtenir
\[
	\lambda_t^k \leq {[\lambda_i^*]}_k := f\left(\sum_{j=1}^D \overline{M}_{kj}\right)
\]

\paragraph{Majorant $\lambda^*$ pour le LSTM} Le calcul est un peu délicat, et n'est pas détaillé dans \autocite{meiEisnerNeuralHawkes} (les seules précisions apportées sont pour le modèle Hawkes non-linéaire).
Chaque composante s'écrit sous la forme d'une somme de termes
\begin{equation}\label{eq:hiddenStateComponent}
	\sum_{j=1}^{D} {[W_l]}_{kj} \underbrace{{[o_i]}_j}_{>0}
	\tanh \left( [\bar{c}_{i}]_j + \left([c_{i}]_j - [\bar{c}_{i}]_j \right)e^{-[\delta_i]_j (t-t_{i-1})}
	\right)
\end{equation}
Le sens de variation de chaque terme dépend du signe de l'élément de $W_l$ et de $c_i - \bar{c_i}$:
\begin{itemize}
	\item Si ${[W_l]}_{kj}{[c_i - \bar{c}_i]}_{j} < 0$ alors le terme correspondant est croissant, et on le majore par sa limite quand $t\to\infty$
	\[
		\overline{M}_{kj} = {[W_l]}_{kj} {[o_i]}_j \tanh \left( [\bar{c}_{i}]_j\right)
	\]
	\item Sinon, le terme est décroissant, et on le majore par sa valeur en $t_{i-1}^{+}$
	\[
		\overline{M}_{kj} = {[W_l]}_{kj} {[o_i]}_j \tanh \left( [c_{i}]_j\right)
	\]
\end{itemize}
Ces majorants restent valables sur tout l'intervalle $(t_{i-1}, t_i]$, et sont calculés à chaque événement. Ils forment une matrice $\overline{M}\in\RR^{K\times D}$. L'expression du majorant de chaque composante est donné en modifiant \eqref{eq:hiddenStateComponent} par
\[
	{[\lambda^{*}]}_k := \sum_{j=1}^{D} \overline{M}_{kj},\quad k\in \llbracket 1, K\rrbracket.
\]

\subsection{Prédiction}

Nous avons calculé l'intégrale dans la densité \eqref{eq:nextIncrementDensity} par méthode d'Euler.

L'indicateur de performance choisi est l'erreur quadratique (RMSE):
\begin{equation}\label{eq:rmse}
	\mathrm{RMSE} = \sqrt{\EE\left[{\left(\hat{t}_i - t_i\right)}^2\right]}
\end{equation}
que l'on estime sur l'ensemble d'entraînement par
\[
	\hat{R}_M = \sqrt{\frac{1}{M}\sum_{m=1}^M
		\left(\hat{t}_i^{(m)} - t_i^{(m)}\right)^2
	}
\]
Par méthode delta, on a
\[
	\sqrt{M}\left(\hat{R}_M - \mathrm{RMSE}\right)
	\approx \mathcal{N}\left(0, \frac{
		\Var\left((\hat{t}_i - t_i)^2\right)}{4 \mathrm{RMSE}}
	\right)
\]
qui permet d'avoir une estimation de la variance de l'estimateur $\hat{R}_M$.


\end{document}