% !TeX spellcheck = fr_FR
\documentclass[../main.tex]{subfiles}

\begin{document}

\section{Algorithmes}\label{sec:algoAppendix}

\subsection{Calcul de la log-vraisemblance}

La log-vraisemblance donnée par la relation \eqref{eq:explicitLikelihood} comporte deux termes: une somme de logarithmes d'intensités et l'intégrale $\int_0^T\lambda_t\,dt$ de l'intensité totale du processus (la somme des intensités de chaque type).

\paragraph{Estimation de l'intégrale.} Étant donné une famille iid de variables aléatoires $\tau^{(m)}\sim\mathcal{U}([0,T])$ indépendantes de la filtration $\mathds{F}$, la quantité 
\[
\bar{\Lambda}_M = \frac{1}{M}\sum_{m=1}^{M}T\lambda_{\tau^{(m)}}\cdot\mathbf 1
\]
est un estimateur non biaisé et convergent de l'intégrale, suggéré dans \cite[16]{meiEisnerNeuralHawkes}. Mais il pose un problème: étant donné que l'expression de $\lambda_t$ est définie par morceaux, il faut savoir à quel intervalle $(t_{i-1}, t_i]$ appartient $\tau$.

En utilisant la relation de Chasles, on peut construire l'estimateur (non biaisé et convergent) suivant:
\begin{equation}
\hat{\Lambda}_M^C = \frac{1}{M}\sum_{m=1}^{M}\left[ \sum_{i=1}^{I} \Delta t_i\lambda_{\tau^{(m)}_i} \cdot \mathbf{1} + (T-t_{I})\lambda_{\tau^{(m)}_{I+1}}\cdot\mathbf{1}\right]
\approx
\int_0^T \lambda_t\,dt
\end{equation}
où les $\tau_i^{(m)}\sim\mathcal{U}([t_{i-1}, t_i])$, $\tau_{I+1}^{(m)}\sim\mathcal{U}([t_I, T])$ sont indépendants. Le problème de l'intervalle auquel appartient $\tau$ est levé, mais on n'a aucune garantie que $\hat{\Lambda}^C$ soit un meilleur ou pire estimateur que $\bar{\Lambda}$ en terme de variance.

\paragraph{Somme des log-intensités.} Le premier terme pose un léger problème au niveau de l'implémentation. Le calcul des intensités ${(\lambda_{t_i})}_i$ donne un tenseur \verb|intens_at_evs| de format $I\times B\times K$, avec $B$ la taille du \textit{batch} (le sous-ensemble d'entraînement que l'on est en train de traiter). Extraire les $\lambda^{k_i}_{t_i}$ ne peut pas se faire par indexation (par exemple en faisant \verb|intens_at_evs[:, :, event_types]|).

L'astuce utilisée exploite la représentation des types $k_i$ par encodage \textit{one-hot} avec des vecteurs $x_i\in{\{0,1\}}^K$. En notant $\odot$ le produit terme-à-terme, la relation
\[
\lambda^{k_i}_{t_i} = \sum_{k=1}^K {(\lambda_{t_i} \odot x_i)}_k,
\]
permet d'obtenir les intensités par produit et réduction.

\end{document}