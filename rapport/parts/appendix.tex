% !TeX spellcheck = fr_FR
\documentclass[../main.tex]{subfiles}

\begin{document}

\section{Algorithmes}\label{sec:algoAppendix}

\subsection{Calcul de la log-vraisemblance}

La log-vraisemblance donnée par la relation \eqref{eq:explicitLikelihood} comporte deux termes: une somme de logarithmes d'intensités et l'intégrale $\int_0^T\lambda_t\cdot\mathbf{1}\,dt$ de l'intensité totale du processus.

\paragraph{Somme des log-intensités.} Le premier terme pose un léger problème au niveau de l'implémentation. Le calcul des intensités ${(\lambda_{t_i})}_i$ donne un tenseur \verb|intens_ti| de format $I\times B\times K$, avec $B$ la taille du \textit{batch} (le sous-ensemble d'entraînement que l'on est en train de traiter). Extraire les $\lambda^{k_i}_{t_i}$ ne peut pas se faire par indexation (par exemple en faisant \verb|intens_ti[:, :, event_types]|).

L'astuce utilisée exploite la représentation des types $k_i$ par encodage \textit{one-hot} avec des vecteurs $u_i\in{\{0,1\}}^K$, définis par $(u_i)_j = \mathds{1}_{\{k_i = j\}}$.\footnotemark En notant $\odot$ le produit terme-à-terme, la relation
\[
\lambda^{k_i}_{t_i} = \sum_{k=1}^K {(\lambda_{t_i} \odot u_i)}_k,
\]
permet d'obtenir les intensités par produit et réduction.
\footnotetext{Ainsi, si $K=3$ et $k_i = 2$, alors $u_i = {(0,1,0)}^\intercal$}


\paragraph{Estimation de l'intégrale.} Étant donné une famille de variables aléatoires iid $\tau^{(m)}\sim\mathcal{U}([0,T])$ indépendantes de la filtration $\mathds{F}$, la quantité 
\[
\bar{\Lambda}_M = \frac{1}{M}\sum_{m=1}^{M}T\lambda_{\tau^{(m)}}\cdot\mathbf 1
\]
est un estimateur non biaisé et convergent de l'intégrale, suggéré dans \cite[16]{meiEisnerNeuralHawkes}. Mais il pose un problème: étant donné que l'expression de $\lambda_t$ est définie par morceaux, il faut savoir à quel intervalle $(t_{i-1}, t_i]$ appartient $\tau$.

En utilisant la relation de Chasles, on peut construire l'estimateur (non biaisé et convergent) suivant:
\begin{equation}
\hat{\Lambda}_M^C = \frac{1}{M}\sum_{m=1}^{M}\left[ \sum_{i=1}^{I} \Delta t_i\lambda_{\tau^{(m)}_i} \cdot \mathbf{1} + (T-t_{I})\lambda_{\tau^{(m)}_{I+1}}\cdot\mathbf{1}\right]
\approx
\int_0^T \lambda_t\,dt
\end{equation}
où les $\tau_i^{(m)}\sim\mathcal{U}([t_{i-1}, t_i])$, $\tau_{I+1}^{(m)}\sim\mathcal{U}([t_I, T])$ sont indépendants. Le problème de l'intervalle auquel appartient $\tau$ est levé, mais on n'a aucune garantie que $\hat{\Lambda}^C$ soit un meilleur ou pire estimateur que $\bar{\Lambda}$ en terme de variance.

\subsection{Simulation de processus}

\paragraph{Algorithme de \textit{thinning}}

\paragraph{Calcul du majorant $\lambda^*$ pour le LSTM} Le calcul est un peu délicat, et n'est pas détaillé dans \autocite{meiEisnerNeuralHawkes} (les seules précisions apportées sont pour le modèle Hawkes non-linéaire).
La fonction d'activation $f$ est toujours strictement croissante, donc il suffit en fait de majorer les composantes de $W_lh(t)$. Chaque composante s'écrit sous la forme d'une somme de termes
\begin{equation}\label{eq:hiddenStateComponent}
	\sum_{j=1}^{D} {[W_l]}_{kj} \underbrace{{[o_i]}_j}_{>0}
	\tanh \left( [\bar{c}_{i}]_j + \left([c_{i}]_j - [\bar{c}_{i}]_j \right)e^{-[\delta_i]_j (t-t_{i-1})}
	\right)
\end{equation}
Le sens de variation de chaque terme dépend du signe de l'élément de $W_l$ et de $c_i - \bar{c_i}$:
\begin{itemize}
	\item Si ${[W_l]}_{kj}{[c_i - \bar{c}_i]}_{j} < 0$ alors le terme correspondant est croissant, et on le majore par sa limite quand $t\to\infty$
	\[
		\overline{M}_{kj} = {[W_l]}_{kj} {[o_i]}_j \tanh \left( [\bar{c}_{i}]_j\right)
	\]
	\item Sinon, le terme est décroissant, et on le majore par sa valeur en $t_{i-1}^{+}$
	\[
		\overline{M}_{kj} = {[W_l]}_{kj} {[o_i]}_j \tanh \left( [c_{i}]_j\right)
	\]
\end{itemize}
Ces majorants restent valables sur tout l'intervalle $(t_{i-1}, t_i]$, et sont calculés à chaque événement. Ils forment une matrice $\overline{M}\in\RR^{K\times D}$. L'expression du majorant de chaque composante est donné en modifiant \eqref{eq:hiddenStateComponent} par
\[
	{[\lambda^{*}]}_k := \sum_{j=1}^{D} \overline{M}_{kj},\quad k\in \llbracket 1, K\rrbracket
\]


\end{document}