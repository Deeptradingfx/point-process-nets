% !TeX spellcheck = fr_FR
\documentclass[11pt]{article}
\usepackage[a4paper,hmargin=3.6cm]{geometry}
\usepackage{subfiles}

\usepackage{mathtools}
\usepackage{amsfonts,amssymb}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{hyperref}

\usepackage{dsfont}

\usepackage{polyglossia}
\usepackage{csquotes}
\usepackage[backend=biber,sorting=nyt]{biblatex}
\setdefaultlanguage{french}

\title{\textbf{Rapport de projet}\\
  \textit{Processus ponctuels récurrents}
}
\author{
  Wilson \textsc{Jallet}\\
  Cheikh \textsc{Fall}\\
  \textit{sous la supervision d'Emmanuel BACRY}
}

\newcommand{\RR}{\mathbb{R}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\EE}{\mathbb{E}}

\bibliography{references.bib}

\begin{document}
\maketitle

\section{Introduction}

On cherche à modéliser des flux d'événements discrets, arrivant à des instants $t_i$ et associés à des \textit{types} $k_i$, et dont l'évolution dépend du passé: des événements de certains types peut en inciter ou \textit{exciter} d'autres (dans le sens où leur arrivée devient plus probable dans le futur). Par exemple, ces événements peuvent être des messages sur un réseau social comme Twitter (le type pourrait alors être la <<~popularité~>> de l'auteur du message, et chaque message en inciterait d'autres sous la forme de \textit{retweets}), ou des ordres sur un marché financier, où les types seraient s'il s'agit d'un achat (\textit{bid}), d'une vente (\textit{ask}), d'une annulation (\textit{cancel}), au prix du marché ou exécuté à partir d'un certain prix.

\section{Modèles}

\subfile{parts/models.tex}


\section{Algorithmes et implémentation}

Les réseaux de neurones sont implémentés en utilisant la librairie \textsf{PyTorch} \cite{paszke2017automatic}, permettant de faire du calcul tensoriel avec différentiation automatique (pour calculer les gradients).

La log-vraisemblance d'une suite d'événements $\{(t_i,x_i)\}_i$ est donnée par la formule
\begin{equation}
\mathcal{L}\left(\{(t_i,k_i)\}_i)\right)
=
\sum_{i:\,t_i < T} \log\lambda^{k_i}_{t_i} - \int_0^T \underbrace{\lambda_t\cdot\mathbf{1}}_{\sum_{k=1}^K\lambda^j_t}\,dt
\end{equation}


\printbibliography

\appendix

\section{Vraisemblance}

On peut démontrer que la log-vraisemblance s'écrit comme dans \eqref{eq:likelihood}.


\end{document}