@article{elman1990srnn,
	author = {Elman, Jeffrey L.},
	title = {Finding Structure in Time},
	journal = {Cognitive Science},
	volume = {14},
	number = {2},
	pages = {179-211},
	year = {1990},
	doi = {10.1207/s15516709cog1402\_1},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog1402_1},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1207/s15516709cog1402_1},
	abstract = {Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves: the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands: indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent, while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction.}
}

@inproceedings{paszke2017automatic,
	title={Automatic differentiation in PyTorch},
	author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	booktitle={NIPS-W},
	year={2017}
}

@article{2015arXiv150204592B,
	author = {{Bacry}, E. and {Mastromatteo}, I. and {Muzy}, J.-F.},
	title = "{Hawkes processes in finance}",
	journal = {ArXiv e-prints},
	archivePrefix = "arXiv",
	eprint = {1502.04592},
	primaryClass = "q-fin.TR",
	keywords = {Quantitative Finance - Trading and Market Microstructure},
	year = 2015,
	month = feb,
	adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150204592B},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{2017arXiv170703003B,
	author = {{Bacry}, E. and {Bompaire}, M. and {Ga{\"i}ffas}, S. and {Poulsen}, S.},
  	title = "{tick: a Python library for statistical learning, with
    a particular emphasis on time-dependent modeling}",
  	journal = {ArXiv e-prints},
  	eprint = {1707.03003},
  	year = 2017,
  	month = jul
}

@article{bowsherModellingMktEvents2002,
	author = {G. Bowsher, Clive},
	year = {2002},
	month = {11},
	pages = {},
	title = {Modelling Security Market Events in Continuous Time: Intensity Based, Multivariate Point Process Models},
	volume = {141},
	journal = {SSRN Electronic Journal},
	doi = {10.2139/ssrn.343020}
}

@misc{unreasonableEffectivenessRNN,
	author = {Andrej Kaparthy},
	title = {The Unreasonable Effectiveness of Recurrent Neural Networks},
	date = {2015-05-21},
	url = {http://karpathy.github.io/2015/05/21/rnn-effectiveness/},
}

@article{meiEisnerNeuralHawkes,
	author    = {Hongyuan Mei and
	Jason Eisner},
	title     = {The Neural Hawkes Process: {A} Neurally Self-Modulating Multivariate
	Point Process},
	journal   = {CoRR},
	volume    = {abs/1612.09328},
	year      = {2016},
	url       = {http://arxiv.org/abs/1612.09328},
	archivePrefix = {arXiv},
	eprint    = {1612.09328},
	timestamp = {Mon, 13 Aug 2018 16:48:23 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/MeiE16},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}